                              ____________

                               P4 WRITEUP
                              ____________


- Name: Jeffrey Do
- NetID: do000043@umn.edu

Answer the questions below according to the project specification. Write
your answers directly in this text file and submit it along with your
code.


PROBLEM 1: matata_OPTM()
========================

  Do your timing study on csel-atlas.cselabs.umn.edu


(A) Paste Source Code
~~~~~~~~~~~~~~~~~~~~~

int matata_VER2(matrix_t mat, matrix_t ans) {
  int lead = 0;   // Intializing variables for later use
  int val0 = 0;
  int val1 = 0;
  int val2 = 0;
  
  int row;
  int i;
  int j;
  
  int mat_rows = mat.rows;
  int mat_cols = mat.cols;

  memset(ans.data, 0, sizeof(int) * mat_rows * mat_cols); // Using memset to bulk change the answer matrix data to 0
 
  for(row = 0; row<mat_rows; row++){
    for(i = 0; i<mat_rows; i++){
      lead = mat.data[row*mat_cols + i];  // Reordering memory access to be sequential to favor cache, working across rows for matrices

      for(j = 0; j<mat_cols-3; j+=3){ // Loop unrolling to favor cache
        val0 = ans.data[i*mat_cols + j] + lead * mat.data[row*mat_cols + j];  // Inline functions instead of macros
        val1 = ans.data[i*mat_cols + j+1] + lead * mat.data[row*mat_cols + j+1];
        val2 = ans.data[i*mat_cols + j+2] + lead * mat.data[row*mat_cols + j+2];

        ans.data[i*mat_cols + j] = val0;
        ans.data[i*mat_cols + j+1] = val1;
        ans.data[i*mat_cols + j+2] = val2;
      }

      for(; j<mat_cols; j++){ // Secondary for loop to deal with the excess
        val0 = ans.data[i*mat_cols + j] + lead * mat.data[row*mat_cols + j];
        ans.data[i*mat_cols + j] = val0;
      }
    }
  }
  return 0;
}


(B) Timing on csel-atlas
~~~~~~~~~~~~~~~~~~~~~~~~

do000043@csel-atlas:~/Desktop/csci2021/p4-code$ ./matata_benchmark 
==== Matrix A^T*A Benchmark Version 1 ====
  SIZE       BASE       OPTM  SPDUP   LOG2 FACTOR POINTS 
   171 3.2201e-02 1.0848e-02   2.97   1.57   1.00   1.57 
   196 4.8541e-02 1.5762e-02   3.08   1.62   1.15   1.86 
   256 1.3440e-01 3.5651e-02   3.77   1.91   1.50   2.87 
   320 2.4502e-01 6.8354e-02   3.58   1.84   1.87   3.45 
   801 4.6050e+00 1.1073e+00   4.16   2.06   4.68   9.63 
  1024 2.3267e+01 2.2961e+00  10.13   3.34   5.99  20.01 
RAW POINTS: 39.38
TOTAL POINTS: 35 / 35


(C) Optimizations
~~~~~~~~~~~~~~~~~

  Describe in some detail the optimizations you used to speed the code
  up.  THE CODE SHOULD CONTAIN SOME COMMENTS already to describe these
  but in the section below, describe in English the techniques you used
  to make the code run faster.  Format your descriptions into discrete
  chunks such as.
        Optimization 1: Blah bla blah... This should make run
        faster because yakkety yakeety yak.

        Optimization 2: Blah bla blah... This should make run
        faster because yakkety yakeety yak.

        ...  Optimization N: Blah bla blah... This should make run
        faster because yakkety yakeety yak.
  Full credit solutions will have a least two optimizations and describe
  WHY these improved performance in at least a couple sentences.

Optimization 1: Using memset to bulk change the answer matrix data to 0.
  This should make the code run faster due not having an extra for loop to
  iterate over the answer matrix.

Optimization 2: Reordering memory access to be sequential to favor cache, 
  working across rows for matrices. The C language uses row-major access for
  arrays and lists. Adjusting the algorithm to walk row-wise fashion to avoid
  stride required for column-wise access.

Optimization 3: Loop unrolling to favor cache. This should speed the code 
  up to take advandage of superscalar and pipeline processes. I found that 
  three copies of the code increased the speed.

Optimization 4: Accessing structs directly instead of macros. Direct access
  is micro-optimization that reduces the some unnessary work used in the 
  macros leading to a small performance increase.

PROBLEM 2: Timing Search Algorithms
===================================

  Do your timing study on csel-atlas.cselabs.umn.edu. In most cases,
  report times larger than 1e-03 seconds as times shorter than this are
  unreliable. Run searches for more repetitions to lengthen run times.


(A) Min Size for Algorithmic Differences
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Determine the size of input array where one starts to see a measurable
  difference in the performance of the linear and logarithmic
  algorithms.  Produce a timing table which includes all algorithms
  which clearly demonstrates an uptick in the times associated with some
  while others remain much lower.  Identify what size this appears to be
  a occur. SHOW A TIMING TABLE to support your conclusions and ensure
  that the times reported are larger that 1e-03.

do000043@csel-atlas:~/Desktop/csci2021/p4-code$ ./search_benchmark 4 6 3000
LENGTH SEARCHES      array       list     binary       tree 
    16       32 5.3360e-03 5.1820e-03 4.8850e-03 3.8820e-03 
    32       64 1.3978e-02 1.4042e-02 1.0959e-02 8.9950e-03 
    64      128 4.6002e-02 4.5989e-02 2.3572e-02 2.0456e-02 

Around length 64 is where there is a measurable difference.

(B) Linear Search in List vs Array
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Determine whether the linear array and linked list search remain
  approximately at the same performance level as size increases to large
  data or whether one begins to become favorable over other. Determine
  the approximate size at which this divergence becomes obvious. Discuss
  reasons WHY this difference arises.  SHOW A TIMING TABLE to support
  your conclusions and ensure that the times reported are larger that
  1e-03.

do000043@csel-atlas:~/Desktop/csci2021/p4-code$ ./search_benchmark 8 10 3000 ll la
LENGTH SEARCHES      array       list 
   256      512 6.5011e-01 6.6104e-01 
   512     1024 2.5530e+00 2.7390e+00 
  1024     2048 1.1414e+01 3.3854e+01 

Around length 1024 is where there is a measurable difference. The reason why the
array performs faster is that the cache favors acessing memory sequentially. Arrays 
allow easy access to the next index since the indexes are stored together in memory.
List indexes may be spread out in memory which can cause dips in performance.

(C) Binary Search in Tree vs Array
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Compare the binary array search and binary tree search on small to
  very large arrays. Determine if there is a size at which the
  performance of these two begins to diverge. If so, describe why this
  might be happening based on your understanding of the data structures
  and the memory system. If not, describe why you believe there is
  little performance difference between the two. SHOW A TIMING TABLE to
  support your conclusions and ensure that the times reported are larger
  that 1e-03.

do000043@csel-atlas:~/Desktop/csci2021/p4-code$ ./search_benchmark 1 15 5000 bt bl
LENGTH SEARCHES     binary       tree 
     2        4 3.6000e-03 3.7350e-03 
     4        8 4.0380e-03 4.0260e-03 
     8       16 4.9810e-03 4.6680e-03 
    16       32 9.7140e-03 7.6640e-03 
    32       64 2.2148e-02 1.8250e-02 
    64      128 4.6753e-02 4.0233e-02 
   128      256 8.7237e-02 7.5525e-02 
   256      512 1.7717e-01 1.4954e-01 
   512     1024 3.6776e-01 2.9235e-01 
  1024     2048 7.8039e-01 6.1292e-01 
  2048     4096 1.5777e+00 1.1901e+00 
  4096     8192 2.9307e+00 2.4329e+00 
  8192    16384 6.3401e+00 5.1573e+00 
 16384    32768 1.3440e+01 1.1520e+01 
 32768    65536 2.9439e+01 2.4140e+01

There is little performance difference between the two at all sizes. Both algorthims
implement the binary search algorithm where it checks if the value is higher or lower than
the current value. The array algorithm does not favor cache since it tries to find the center 
after each operation, and the how the lists order thier memory also does not favor cache at all. 
However, both algorithms are O(log n) which is faster than then O(n) algorthims linear array and
list search. The tree has a slight performance increase possibly due to the less work required 
to move left or right across the tree while the array needs to calculate the center. 

(D) Caching Effects on Algorithms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  It is commonly believed that memory systems that feature a Cache will
  lead to arrays performing faster than linked structures such as Linked
  Lists and Binary Search Trees. Describe whether your timings confirm
  or refute this belief.  Address both types of algorithms in your
  answer:
  - What effects does Cache have on Linear Search in arrays and lists
    and why?
  - What effects does Cache have on Binary Search in arrays and trees
    and why?

As previously mentioned, the effect on cache lead to arrays performing 
better than list in linear search due to how arrays and lists are stored
in memory. Since cache favor sequential access, arrays will perform faster
than lists.

In Binary search, both algorithms do not favor cache causing the cache to not affect
preformance. The array tries to find the center of the array in each opertion, which does 
not favor cache. As previously mentioned,both algorithms are O(log n) which is faster than 
then O(n) algorthims linear array and list search. The tree has a slight performance 
increase possibly due to the less work required to move left or right across the tree while
 the array needs to calculate the center. 

(E) OPTIONAL MAKEUP CREDIT
~~~~~~~~~~~~~~~~~~~~~~~~~~

  If you decided to make use of a table of function pointers/structs
  which is worth makeup credit, describe your basic design for this
  below.

  ####################### YOUR ANSWER HERE #########################

  ##################################################################
